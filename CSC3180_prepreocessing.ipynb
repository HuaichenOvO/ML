{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC3180_prepreocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOK+jUHaB9TYWzaH7fEvGX6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuaichenOvO/ML/blob/main/CSC3180_prepreocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gKVujwdNhDnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d94301-7651-4e23-d31c-d270031ed3da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
            "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
            "  \"found relative to the 'datapath' directory.\".format(key))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "traVP3-nveOW"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "DATA_HUB = dict()\n",
        "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
        "\n",
        "def download(name, cache_dir=os.path.join('..', 'data')): \n",
        "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名。\"\"\"\n",
        "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}.\"\n",
        "    url, sha1_hash = DATA_HUB[name]\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        sha1 = hashlib.sha1()\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "                sha1.update(data)\n",
        "        if sha1.hexdigest() == sha1_hash:\n",
        "            return fname  # Hit cache\n",
        "    print(f'正在从{url}下载{fname}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(name, folder=None):\n",
        "    fname = download(name)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    elif ext in ('.tar', '.gz'):\n",
        "        fp = tarfile.open(fname, 'r')\n",
        "    else:\n",
        "        assert False, '只有zip/tar文件可以被解压缩。'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n",
        "\n",
        "def download_all():\n",
        "    \"\"\"下载DATA_HUB中的所有文件。\"\"\"\n",
        "    for name in DATA_HUB:\n",
        "        download(name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install d2l\n",
        "# !pip install matplotlib==3.0.0\n",
        "# !pip install --upgrade mxnet\n",
        "# !pip install autogluon\n",
        "# !pip install torch\n",
        "# # !pip install d2l.torch"
      ],
      "metadata": {
        "id": "vW9qZIcqaSsR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "DATA_HUB['kaggle_house_train'] = (  \n",
        "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
        "    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
        "\n",
        "DATA_HUB['kaggle_house_test'] = (  \n",
        "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
        "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n",
        "\n",
        "train_data = pd.read_csv(download('kaggle_house_train'))\n",
        "test_data = pd.read_csv(download('kaggle_house_test'))"
      ],
      "metadata": {
        "id": "N_RSXvJLaLcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd1508c-6bf3-495a-da69-3edb8ebe432c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载../data/kaggle_house_pred_train.csv...\n",
            "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载../data/kaggle_house_pred_test.csv...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NN's preprocessing\n",
        "\"\"\"\n",
        "\n",
        "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
        "all_features.shape\n",
        "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
        "all_features[numeric_features] = all_features[numeric_features].apply(\n",
        "    lambda x: (x - x.mean()) / (x.std()))\n",
        "# after normalisation, the mean disappear, so we can set the null space to 0.\n",
        "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
        "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
        "all_features.astype(float)\n",
        "all_features.shape\n",
        "n_train = train_data.shape[0]\n",
        "train_features = torch.tensor(all_features[:n_train].values, dtype=d2l.float32)\n",
        "test_features = torch.tensor(all_features[n_train:].values, dtype=d2l.float32)\n",
        "train_labels = np.log(torch.tensor(\n",
        "    train_data.SalePrice.values.reshape(-1, 1), dtype=d2l.float32))\n",
        "\n",
        "\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "in_features = train_features.shape[1]\n",
        "\n",
        "def get_net():\n",
        "    net = nn.Sequential(nn.Linear(in_features,1))\n",
        "    return net\n",
        "\n",
        "def log_rmse(net, features, labels):\n",
        "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
        "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
        "    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n",
        "                           torch.log(labels)))\n",
        "    return rmse.item()\n",
        "\n",
        "def train(net, train_features, train_labels, test_features, test_labels,\n",
        "          num_epochs, learning_rate, weight_decay, batch_size):\n",
        "    train_ls, test_ls = [], []\n",
        "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
        "    # 这里使用的是Adam优化算法\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr = learning_rate,\n",
        "                                 weight_decay = weight_decay)\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "            l = loss(net(X), y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
        "        if test_labels is not None:\n",
        "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
        "    return train_ls, test_ls\n",
        "\n",
        "def get_k_fold_data(k, i, X, y):\n",
        "    assert k > 1\n",
        "    fold_size = X.shape[0] // k\n",
        "    X_train, y_train = None, None\n",
        "    for j in range(k):\n",
        "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
        "        X_part, y_part = X[idx, :], y[idx]\n",
        "        if j == i:\n",
        "            X_valid, y_valid = X_part, y_part\n",
        "        elif X_train is None:\n",
        "            X_train, y_train = X_part, y_part\n",
        "        else:\n",
        "            X_train = torch.cat([X_train, X_part], 0)\n",
        "            y_train = torch.cat([y_train, y_part], 0)\n",
        "    return X_train, y_train, X_valid, y_valid\n",
        "\n",
        "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n",
        "           batch_size):\n",
        "    train_l_sum, valid_l_sum = 0, 0\n",
        "    for i in range(k):\n",
        "        data = get_k_fold_data(k, i, X_train, y_train)\n",
        "        net = get_net()\n",
        "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
        "                                   weight_decay, batch_size)\n",
        "        train_l_sum += train_ls[-1]\n",
        "        valid_l_sum += valid_ls[-1]\n",
        "        if i == 0:\n",
        "            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n",
        "                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],\n",
        "                     legend=['train', 'valid'], yscale='log')\n",
        "        print(f'fold {i + 1}, train log rmse {float(train_ls[-1]):f}, '\n",
        "              f'valid log rmse {float(valid_ls[-1]):f}')\n",
        "    return train_l_sum / k, valid_l_sum / k"
      ],
      "metadata": {
        "id": "Cl0OnPCEFDzw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "数据可视化 了解大概印象\n",
        "\"\"\"\n",
        "\n",
        "# train_data.info()\n",
        "# train_data.head(2)\n",
        "# train_data['SalePrice']\n",
        "\n",
        "# 热区图\n",
        "corrmat = train_data.corr()\n",
        "plt.subplots(figsize = (13,10))\n",
        "sns.heatmap(corrmat)"
      ],
      "metadata": {
        "id": "j_ZNYr5KeEDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "数据insight\n",
        "\"\"\"\n",
        "# train_data.describe().T\n",
        "# train_data.describe(include='object').T\n",
        "\n",
        "corr = train_data.corr()\n",
        "# plt.figure(figsize=(20,20))\n",
        "# sns.heatmap(corr,annot=True)\n",
        "\n",
        "corr_arr=corr[\"SalePrice\"].sort_values(ascending=False)\n",
        "corr_arr=pd.DataFrame(corr_arr)\n",
        "corr_arr.head(11)\n",
        "\n"
      ],
      "metadata": {
        "id": "ERwsDZQO_-re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "数据清洗：去除无关attribute\n",
        "\"\"\"\n",
        "\n",
        "# train_data.drop(columns=['Id'],axis=1,inplace=True)\n",
        "# train_data.drop(columns=['Id'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "g9SPDsGJBR_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37d790e6-6d35-422b-f789-4c88da238d74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n数据清洗：去除无关attribute\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "预处理\n",
        "1. 将已经是数值化的数据normalize\n",
        "2. fill object value by None without null value.\n",
        "\"\"\"\n",
        "from copy import deepcopy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = deepcopy(train_data)\n",
        "test = deepcopy(test_data)\n",
        "\n",
        "def myPreprocessing(data_set):\n",
        "    # 1. 标准化数值类型的数据\n",
        "    # after normalisation, the mean disappear, \n",
        "    # so we can set the null space to 0.\n",
        "    numeric_features = data_set.dtypes[data_set.dtypes != 'object'].index\n",
        "    data_set[numeric_features] = data_set[numeric_features].apply(\n",
        "        lambda x: (x - x.mean()) / (x.std()))\n",
        "    data_set[numeric_features] = data_set[numeric_features].fillna(0)\n",
        "\n",
        "    # 2. 将非数值类型的数据encode\n",
        "    object_cols=data_set.select_dtypes(include='object')\n",
        "    le = LabelEncoder()\n",
        "    for i in object_cols:\n",
        "        data_set[i]=le.fit_transform(data_set[i])\n",
        "\n",
        "    data_set.astype(float)\n",
        "\n",
        "\n",
        "# split train_x and train_y\n",
        "myPreprocessing(train)\n",
        "x = train.drop(['Id','SalePrice'], axis = 1)\n",
        "y = train[['SalePrice']]\n",
        "\n",
        "# there is no null data left\n",
        "print(train.shape)\n",
        "# print(y.isnull().sum().max())\n",
        "\n",
        "\n",
        "print(train.head(5))\n",
        "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rBBi7PWv1kIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对 test 做同样的处理\n",
        "\n",
        "myPreprocessing(test)\n",
        "\n",
        "test.shape\n",
        "# print(test.isnull().sum().max())\n",
        "\n",
        "# print(test.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6DT-YBefs0m",
        "outputId": "bb46e5d2-ce2c-45ef-8b80-c8a064137659"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error "
      ],
      "metadata": {
        "id": "xko6jHMTOyey"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Linear Neuron Network\n",
        "\"\"\"\n",
        "\n",
        "k, num_epochs, lr, weight_decay, batch_size = 5, 150, 5, 0, 64\n",
        "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
        "                          weight_decay, batch_size)\n",
        "print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n",
        "      f'平均验证log rmse: {float(valid_l):f}')\n"
      ],
      "metadata": {
        "id": "4fKsOr01QPG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Linear Regression\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "k = 5\n",
        "for i in range(k):\n",
        "    \n",
        "    X_train, y_train, X_val, y_val = get_k_fold_data(k,i,train_features,train_labels)\n",
        "\n",
        "    regressor = LinearRegression()\n",
        "    fit = regressor.fit(X_train, y_train)\n",
        "    y_pred = fit.predict(X_val)\n",
        "\n",
        "    RMSE_score = mean_squared_error(y_val, y_pred, squared = False)\n",
        "    print(RMSE_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnatD6hDD9P_",
        "outputId": "54854faf-a8f4-4679-ba20-2fc98cda7d3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7253234\n",
            "2.2083502\n",
            "0.16913046\n",
            "1.6825513\n",
            "2.6392121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Catboost Regression \n",
        "\"\"\"\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "k = 5\n",
        "for i in range(k):\n",
        "    X_train, y_train, X_val, y_val = get_k_fold_data(5,i,train_features,train_labels)\n",
        "    X_train = pd.DataFrame(X_train.numpy())\n",
        "    y_train = pd.DataFrame(y_train.numpy())\n",
        "    X_val = pd.DataFrame(X_val.numpy())\n",
        "    y_val = pd.DataFrame(y_val.numpy())\n",
        "\n",
        "    catb_reg = CatBoostRegressor(iterations=3500,verbose=1000)\n",
        "    fit = catb_reg.fit(X_train, y_train)\n",
        "    y_pred = fit.predict(X_val)\n",
        "\n",
        "    RMSE_score = mean_squared_error(y_val, y_pred, squared = False)\n",
        "    print(str(i), \"- fold \", \"RMSE_score = \", RMSE_score)\n",
        "    print('--'*10)"
      ],
      "metadata": {
        "id": "sWl8bf_jtw7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "XGBoost Regression \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "k = 5\n",
        "for i in range(k):\n",
        "    X_train, y_train, X_val, y_val = get_k_fold_data(5,i,train_features,train_labels)\n",
        "    X_train = pd.DataFrame(X_train.numpy())\n",
        "    y_train = pd.DataFrame(y_train.numpy())\n",
        "    X_val = pd.DataFrame(X_val.numpy())\n",
        "    y_val = pd.DataFrame(y_val.numpy())\n",
        "\n",
        "    xgb_reg = XGBRegressor(n_estimators=3000, learning_rate=0.005)\n",
        "    fit = xgb_reg.fit(X_train, y_train)\n",
        "    y_pred = fit.predict(X_val)\n",
        "\n",
        "    RMSE_score = mean_squared_error(y_val, y_pred, squared = False)\n",
        "    print(str(i), \"- fold \", \"RMSE_score = \", RMSE_score)\n",
        "    print('--'*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OABnbE09QEyU",
        "outputId": "c2238444-8581-4079-b6e1-e3507dc942d0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -fold  RMSE_score =  0.114501305\n",
            "--------------------\n",
            "1 -fold  RMSE_score =  0.14088348\n",
            "--------------------\n",
            "2 -fold  RMSE_score =  0.13448845\n",
            "--------------------\n",
            "3 -fold  RMSE_score =  0.12526934\n",
            "--------------------\n",
            "4 -fold  RMSE_score =  0.129139\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}